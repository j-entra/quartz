---
title: "{{title}}"
---
[[_Index]] | [[Machine Learning]]

%% ---
alias: [" "]
--- %%
%% - metadata
	- tags: #
	- source: https://royalsocietypublishing.org/doi/10.1098/rsif.2017.0792
	- fr: 
%%

# Markov Blanket

- In [[Statistics]]/[[Probability]] and machine learning, **Markov Blankets** are a formal property of nodes in a [[Bayesian Probability|Bayesian network]]. They designate a set of nodes that essentially shield a random variable (or a set of variables) from the rest of the variables
- [[Christopher Frith]]: “a cognitive version of a cell membrane, shielding states inside the blanket from states outside.”

Readings:
  
- [The Markov blankets of life: autonomy, active inference and the free energy principle](https://royalsocietypublishing.org/doi/10.1098/rsif.2017.0792)
	- (i) any living system is a Markov blanketed system and 
	- (ii) the boundaries of such systems need not be co-extensive with the biophysical boundaries of a living organism. 
	- In other words, autonomous systems are hierarchically composed of Markov blankets of Markov blankets—all the way down to individual cells, all the way up to you and me, and all the way out to include elements of the local environment.
	- Relates to [[Process Philosophy]], in some way. I think. Or maybe is discounting it, since "Statistically, the existence of a Markov blanket means external states are conditionally independent of internal states, and vice versa, as internal and external states can only influence each other via sensory and active states."
	- external states cause sensory states, which influence internal states
	- internal states cause active states, which influence external states
	- each state influences the other
	- In neuroscience, Markov blankets are at each level of the brain's hierarchy (aka, the brain is a hierarchical [[Bayesian Probability|Baynesian network]] — what [[Geoffrey Hinton]] said.)
	- [[Predictive Coding]]
	- Imagine a creature confronted with a riverbank: in the absence of any prior beliefs about what it would be like to be in the water, the river holds an epistemic affordance (i.e. novelty), in the sense that entering the water resolves uncertainty about ‘what would happen if I did that’. If the unfortunate creature subsequently drowned, priors would emerge (with a bit of natural selection) in her conspecifics that water is not a natural habitat. A few generations down the line, the creature, when confronted with a riverbank, will maintain a safe distance in virtue of avoiding expected surprise, i.e. fulfilling the prior belief that ‘creatures like me are not found in water.’
	- Isn't this just [[Natural Selection]]? But also, how can I relate this to [[Collective Unconscious]].
	- Aim of life: predictability. Aka, knowing all the answers. That makes complete sense to me.

-------------
### See also
[[Free Energy Principle]] [[Active Inference]]

